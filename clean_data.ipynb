{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create paths for the different files\n",
    "\n",
    "ndjson_files = glob.glob(os.path.join(os.getcwd() + r\"\\\\data\", \"*ndjson.gz\"))\n",
    "csv_files = glob.glob(os.path.join(os.getcwd() + r\"\\\\data\", \"*csv.gz\"))\n",
    "print(f\"json files: {ndjson_files}\")\n",
    "print(f\"csv files: {csv_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename (path_name):\n",
    "    # function that creates a new folder called \"fixed\" where to save the fixed files\n",
    "    dir_path, filename = os.path.split(path_name)\n",
    "    \n",
    "    new_dir_path = os.path.join(dir_path, 'fixed')\n",
    "    \n",
    "    if not os.path.exists(new_dir_path):\n",
    "        os.mkdir(new_dir_path)\n",
    "    \n",
    "    new_file_path = os.path.join(new_dir_path, filename[:-3])\n",
    "    \n",
    "    if new_file_path[-3:] != 'csv':\n",
    "        new_file_path = new_file_path[:-7] + \".csv\"\n",
    "    \n",
    "    return new_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_cleaner(csv_files):\n",
    "    # a function to load the CSV-files and clean them, save into Fixed folder\n",
    "    for i in csv_files:\n",
    "        # load csv-file, replace double comma with single comma, and split column into 4 columns.\n",
    "        df = pd.read_csv(i, compression='gzip',sep=\"\\t\", header=None)\n",
    "        df = df.replace(',,', ',')\n",
    "        df[['cl1', 'cl2', 'cl3', 'cl4']] = df.iloc[:, 0].str.split(',', expand=True)\n",
    "        \n",
    "        df = df.fillna('')\n",
    "        \n",
    "        # combine column cl3 and cl4 (2 gender columns) into 1\n",
    "        df['cl5'] = df['cl3'] + df['cl4']\n",
    "        \n",
    "        # only keep relevant columns user_id, country and gender (the combined)\n",
    "        df = df.iloc[:, [1,2,5]]\n",
    "        \n",
    "        # while loading the csv-file we didnt use the header, now we create header based on value in row 1\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df.drop(df.index[0])\n",
    "\n",
    "        # error in country column, mix of upper and lower case, and Sweden and Sverige both exist in the column\n",
    "        df = df.replace('', np.nan)\n",
    "        df['country'] = df['country'].str.lower()\n",
    "        df['country'] = df['country'].replace('sverige', 'sweden')\n",
    "    \n",
    "        print(df.info())\n",
    "        print(\"\")\n",
    "        \n",
    "        new_file = filename(i)\n",
    "        df.to_csv(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndjson_cleaner(ndjson_files):\n",
    "    # a function to load the ndjson-files and save them as CSV-files into Fixed folder\n",
    "    for i in ndjson_files:\n",
    "        df = pd.read_json(i, lines=True)\n",
    "        new_file = filename (i)\n",
    "        df.to_csv(new_file)\n",
    "        print(df.info())\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_cleaner(csv_files)\n",
    "ndjson_cleaner(ndjson_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c853e5d7f049679f46ee365c77fec8b4943e16b81c53fe6075b18d122fe67c7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
